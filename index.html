<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Lei Wu (吴磊)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Lei Wu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="publication.html">Publications</a></div>
<div class="menu-item"><a href="course.html">Courses</a></div>
<div class="menu-item"><a href="group.html">Group</a></div>
<div class="menu-item"><a href="https://pku-fomi.github.io/">Seminar</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Lei Wu (吴磊)</h1>
</div>
<table class="imgtable"><tr><td>
<img src="leiwu.jpeg" alt="Lei Wu" width="120 px" height="160 px" />&nbsp;</td>
<td align="left"><p><br />
Assistant Professor <br /> 
<a href="https://www.math.pku.edu.cn/" target=&ldquo;blank&rdquo;>School of Mathematical Sciences</a> <br /> 
<a href="https://cmlr.pku.edu.cn//" target=&ldquo;blank&rdquo;>Center for Machine Learning Research</a> <br /> 
<a href="https://english.pku.edu.cn/" target=&ldquo;blank&rdquo;>Peking University</a>
</p>
<p>Office: 静园6院  205<br />
Email: leiwu (at) math (dot) pku (dot) edu (dot) cn<br />
</p>
<p><a href="https://scholar.google.com/citations?user=CMweeYcAAAAJ&amp;hl=en" target=&ldquo;blank&rdquo;>Google Scholar</a> &nbsp;&nbsp;&nbsp; <a href="https://github.com/leiwu0" target=&ldquo;blank&rdquo;>Github</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="./cv.pdf" target=&ldquo;blank&rdquo;>CV</a><br />
</p>
</td></tr></table>
<h2>About Me</h2>
<p>I am  currently an Assistant Professor in the <a href="https://www.math.pku.edu.cn" target=&ldquo;blank&rdquo;>School of Mathematical Sciences</a> and  <a href="https://cmlr.pku.edu.cn" target=&ldquo;blank&rdquo;>Center for Machine Learning Research</a> at <a href="https://www.pku.edu.cn/" target=&ldquo;blank&rdquo;>Peking University</a>. 
</p>
<p>Previously, I was a postdoc in PACM  at  Princeton University and in the Wharton Statistics and Data Science Department at the University of Pennsylvania.  I completed my Ph.D. in computational mathematics at Peking University in 2018, advised by  Prof. Weinan E. I received my B.S. degree in  mathematics from  Nankai University in 2012. 
</p>
<p>My research aims to understand the mechanisms behind the success of deep learning, with a particular focus on:
</p>
<ul>
<li><p>The approximation and representation power of neural networks
</p>
</li>
</ul>
<ul>
<li><p>The dynamical behavior of popular optimization algorithms such as SGD and Adam
</p>
</li>
</ul>
<ul>
<li><p>Emergent phenomena in the training of large language models (LLMs)
</p>
</li>
</ul>
<h2>Recruiting</h2>
<p>We are actively seeking self-motivated postdocs, PhD students and interns to join our team. If you are interested in collaborating with me, please send an email to me with your CV and transcript as well as a brief description of your research interests.
</p>
<h2>Selected Works</h2>
<ul>
<li><p><b></b>Understanding and improving LLM pre-training<b></b> 
</p>
<ul>
<li><p>Optimizer design: 
</p>
<ul>
<li><p><a href="https://arxiv.org/abs/2405.20763" target=&ldquo;blank&rdquo;>AdmIRE</a>: Speeds up training by reducing sharpness.
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2502.19002" target=&ldquo;blank&rdquo;>Blockwise LR</a>: A principle for setting learning rates in a blockwise manner.
</p>
</li>
<li><p><a href="https://arxiv.org/abs/2505.24275" target=&ldquo;blank&rdquo;>GradPower</a>: Boosts base optimizers using a sign-power transform, requiring only a single-line code change.
</p>
</li>
</ul>

</li>
</ul>

</li>
</ul>
<ul>
<li><p><b>A stability theory of implicit regularization</b>
</p>
<ul>
<li><p>SGD prefers flat minima via stability: Introduced the <b></b><b>stability-based view of flatness bias</b><b></b>: <a href="http://papers.nips.cc/paper/8049-how-sgd-selects-the-global-minima-in-over-parameterized-learning-a-dynamical-stability-perspective" target=&ldquo;blank&rdquo;>NeurIPS 2018</a>
</p>
</li>
<li><p>The anisotropic  SGD noise is crucial for sharpness control.: <a href="https://arxiv.org/abs/2207.02628" target=&ldquo;blank&rdquo;>NeurIPS 2022</a>
</p>
</li>
<li><p>Flat minima provably generalize well for two-layer ReLU and diagonal linear nets: <a href="https://arxiv.org/abs/2305.17490" target=&ldquo;blank&rdquo;>ICML 2023</a>
</p>
</li>
<li><p>Stability-inspired algorithms for seeking flatter minima <a href="https://arxiv.org/abs/2405.20763" target=&ldquo;blank&rdquo;>NeurIPS 2024</a>
</p>
</li>
<li><p>Discovery of the <b></b><b>Edge of Stability (EoS)</b><b></b> phenomenon: <a href="http://papers.nips.cc/paper/8049-how-sgd-selects-the-global-minima-in-over-parameterized-learning-a-dynamical-stability-perspective" target=&ldquo;blank&rdquo;>NeurIPS 2018</a>
</p>
</li>
</ul>

</li>
</ul>
<ul>
<li><p>Approximation theory for machine learning 
</p>
<ul>
<li><p>Kernel and random features: <a href="https://arxiv.org/abs/2305.05642" target=&ldquo;blank&rdquo;>AoS 2025</a>, <a href="https://arxiv.org/abs/2402.15718" target=&ldquo;blank&rdquo;>arXiv 2024</a>
</p>
</li>
<li><p>Barron space theory for neural networks: <a href="https://arxiv.org/abs/1810.06397" target=&ldquo;blank&rdquo;>CMS 2019</a>, <a href="https://arxiv.org/abs/1906.08039" target=&ldquo;blank&rdquo;>Contr. Appr. 2021</a>,  <a href="https://arxiv.org/abs/2108.04964" target=&ldquo;blank&rdquo;>JMLR 2022</a>, <a href="https://arxiv.org/abs/2305.19082" target=&ldquo;blank&rdquo;>JML 2023</a>, <a href="https://arxiv.org/abs/2305.05642" target=&ldquo;blank&rdquo;>AoS 2025</a>
</p>
</li>
<li><p>Deep CNNs: <a href="https://arxiv.org/abs/2305.08404" target=&ldquo;blank&rdquo;>NeurIPS 2023</a>
</p>
</li>
</ul>

</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2025-06-08, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
