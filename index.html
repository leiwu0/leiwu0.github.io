<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN"
  "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">
<head>
<meta name="generator" content="jemdoc, see http://jemdoc.jaboc.net/" />
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<link rel="stylesheet" href="jemdoc.css" type="text/css" />
<title>Lei Wu (吴磊)</title>
</head>
<body>
<table summary="Table for page layout." id="tlayout">
<tr valign="top">
<td id="layout-menu">
<div class="menu-category">Lei Wu</div>
<div class="menu-item"><a href="index.html" class="current">Home</a></div>
<div class="menu-item"><a href="publication.html">Publications</a></div>
<div class="menu-item"><a href="course.html">Courses</a></div>
<div class="menu-item"><a href="group.html">Group</a></div>
</td>
<td id="layout-content">
<div id="toptitle">
<h1>Lei Wu (吴磊)</h1>
</div>
<table class="imgtable"><tr><td>
<img src="leiwu.jpeg" alt="Lei Wu" width="120 px" height="160 px" />&nbsp;</td>
<td align="left"><p><br />
Assistant Professor <br /> 
<a href="https://www.math.pku.edu.cn/" target=&ldquo;blank&rdquo;>School of Mathematical Sciences</a> <br /> 
<a href="https://cmlr.pku.edu.cn//" target=&ldquo;blank&rdquo;>Center for Machine Learning Research</a> <br /> 
<a href="https://english.pku.edu.cn/" target=&ldquo;blank&rdquo;>Peking University</a>
</p>
<p>Office: 静园6院  205<br />
Email: leiwu (at) math (dot) pku (dot) edu (dot) cn<br />
</p>
<p><a href="https://scholar.google.com/citations?user=CMweeYcAAAAJ&amp;hl=en" target=&ldquo;blank&rdquo;>Google Scholar</a> &nbsp;&nbsp;&nbsp; <a href="https://github.com/leiwu0" target=&ldquo;blank&rdquo;>Github</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <a href="./cv.pdf" target=&ldquo;blank&rdquo;>CV</a><br />
</p>
</td></tr></table>
<h2>About Me</h2>
<p>I am  currently an Assistant Professor in the <a href="https://www.math.pku.edu.cn" target=&ldquo;blank&rdquo;>School of Mathematical Sciences</a> and  <a href="https://cmlr.pku.edu.cn" target=&ldquo;blank&rdquo;>Center for Machine Learning Research</a> at <a href="https://www.pku.edu.cn/" target=&ldquo;blank&rdquo;>Peking University</a>. 
</p>
<p>Previously, I was a postdoc in PACM  at  Princeton University and in the Wharton Statistics and Data Science Department at the University of Pennsylvania.  I completed my Ph.D. in computational mathematics at Peking University in 2018, advised by  Prof. Weinan E. I received my B.S. degree in  mathematics from  Nankai University in 2012. 
</p>
<p>My current research focuses  on understanding the mechanisms behind machine and deep learning, specifically: 
</p>
<ul>
<li><p>The approximation and representation power of neural networks
</p>
</li>
<li><p>The convergence and implicit bias of optimization algorithms like SGD and Adam
</p>
</li>
<li><p>The emergent phenomena observed in the training of LLMs
</p>
</li>
</ul>
<h2>Recruiting</h2>
<p>We are actively seeking self-motivated postdocs, PhD students and interns to join our team. If you are interested in collaborating with me, please send an email to me with your CV and transcript as well as a brief description of your research interests.
</p>
<h2>Selected Publications</h2>
<ul>
<li><p><a href="https://arxiv.org/abs/2305.05642" target=&ldquo;blank&rdquo;>A duality framework for analyzing random feature  and two-layer neural networks</a><br />
(α-β) Hongrui Chen, Jihao Long, Lei Wu<br />
Annals of Statistics (to appear), 2025.
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2305.08404" target=&ldquo;blank&rdquo;>Theoretical analysis of inductive biases in deep convolutional networks</a><br />
Zihao Wang, Lei Wu<br /> 
NeurIPS 2023.
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2305.17490" target=&ldquo;blank&rdquo;>The implicit regularization of dynamical stability in stochastic gradient descent</a><br />
Lei Wu, Weijie J. Su<br />
ICML 2023.
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/2207.02628" target=&ldquo;blank&rdquo;>The alignment property of SGD noise and how it helps select flat minima: A stability analysis</a><br />
Lei Wu, Mingze Wang, Weijie J. Su<br />
NeurIPS 2022.
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1906.08039" target=&ldquo;blank&rdquo;>The Barron space and flow-induced function spaces for neural network models</a> <br />
(α-β) Weinan E, Chao Ma, Lei Wu <br /> 
Constructive Approximation, 2021.
</p>
</li>
</ul>
<ul>
<li><p><a href="https://arxiv.org/abs/1904.04326" target=&ldquo;blank&rdquo;>A comparative analysis of the optimization and generalization property of two-layer neural network and random feature models under gradient descent dynamics</a><br />
(α-β) Weinan E, Chao Ma, Lei Wu<br />
Science China Mathematics, 2020.
</p>
</li>
</ul>
<ul>
<li><p><a href="http://papers.nips.cc/paper/8049-how-sgd-selects-the-global-minima-in-over-parameterized-learning-a-dynamical-stability-perspective" target=&ldquo;blank&rdquo;>How SGD selects the global minima in over-parameterized learning: A dynamical stability perspective</a> <br />
Lei Wu, Chao Ma, Weinan E<br /> 
NeurIPS 2018.
</p>
</li>
</ul>
<div id="footer">
<div id="footer-text">
Page generated 2025-05-27, by <a href="https://github.com/wsshin/jemdoc_mathjax" target="blank">jemdoc+MathJax</a>.
</div>
</div>
</td>
</tr>
</table>
</body>
</html>
